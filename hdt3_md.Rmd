---
title: "Hoja3_MD"
author: "Alejandra Guzman, Mariana David, Jorge Caballeros"
date: "2023-03-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



***Ejericicio 7 ***
Seleccione  una  de  las  variables  y  haga  un  modelo  univariado  de  regresión  lineal  para 
predecir  el  precio  de  las  casas.  Analice  el  modelo  (resumen,  residuos,  resultados  de  la 
predicción). Muéstrelo gráficamente. 

Variable seleccionada: GrLivArea

Se puede determinar por el resultado la variable escogifa es significativa para la prediccion de venta de casas (p-valor < 2e-16). La pendiente de la regresion
indica que, en promedio, cad pue cuadrado adicinal de área habitable aumenta el precio de venta en $107.13


```{r}
datos <- read.csv("train.csv")
modelo <- lm(SalePrice ~ GrLivArea, data = datos)
summary(modelo)


```

La siguiente gráfica se utilizo para analizar los residuos del modelo, sugiriendo que el modelo podría no estar capturando completamente la relación entre "GrLivArea" 
y "SalePrice", o que podría haber otras variables que influyen en la relación.

```{r}
datos <- read.csv("train.csv")
modelo <- lm(SalePrice ~ GrLivArea, data = datos)
plot(modelo, which = 1)
predicciones <- predict(modelo, newdata = datos)

```


La gráfica muestra valores observados como puntos y la predicción como una línea roja, se puede ver la relación entre saleprice y grlivarea, la forma de U invertida
sugiere que podrían haber factores que influyen la relación.

```{r}
datos <- read.csv("train.csv")
modelo <- lm(SalePrice ~ GrLivArea, data = datos)
predicciones <- predict(modelo, newdata = datos)
library(ggplot2)
ggplot(data = datos, aes(x = GrLivArea, y = SalePrice)) +
  geom_point() +
  geom_line(aes(y = predicciones), color = "red") +
  labs(title = "Modelo de regresión lineal para predecir el precio de las casas",
       x = "Área habitable (pies cuadrados)", y = "Precio de venta")
```

***Ejericicio 8 ***Haga un modelo de regresión lineal con todas las variables numéricas para predecir el precio de las casas. Analice el modelo (resumen, residuos, resultados de la predicción). Muestre el modelo gráficamente.



```{r}

train <- read.csv("train.csv")
library(caret)

set.seed(123)
trainIndex <- createDataPartition(train$SalePrice, p = 0.8, list = FALSE)
trainData <- train[trainIndex, ]
testData <- train[-trainIndex, ]

lm_model <- lm(SalePrice ~ ., data = trainData[, sapply(trainData, is.numeric)])

#variables significativas
summary(lm_model)

par(mfrow = c(2,2))
plot(lm_model)

predictions <- predict(lm_model, testData[, sapply(testData, is.numeric)])

plot(predictions, testData$SalePrice)
abline(0,1)
```

***Ejericicio 9 *** Analice el modelo. Determine si hay multicolinealidad entre las variables, y cuáles son las que aportan al modelo, por su valor de significación. Haga un análisis de correlación de las características del modelo y especifique si el modelo se adapta bien a los datos. Explique si hay sobreajuste (overfitting) o no. En caso de existir sobreajuste, haga otro modelo que lo corrija. 

```{r}


train <- read.csv("train.csv")
library(caret)

set.seed(123)
trainIndex <- createDataPartition(train$SalePrice, p = 0.8, list = FALSE)
trainData <- train[trainIndex, ]
testData <- train[-trainIndex, ]
correlations <- cor(trainData[, sapply(trainData, is.numeric)])

# Visualizar la matriz de correlación 
library(ggplot2)
library(reshape2)

ggplot(melt(correlations), aes(x = Var1, y = Var2, fill = value)) + 
  geom_tile() +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  ggtitle("Matriz de correlación")

```




En general, podemos decir que el modelo se ajusta bien a los datos, ya que podemos ver algunas correlaciones fuertes entre las características del modelo y la variable objetivo "SalePrice". Sin embargo, también hay algunas características altamente correlacionadas entre sí, lo que sugiere que podríamos considerar la eliminación de algunas de estas características para mejorar el rendimiento del modelo y reducir la complejidad.


```{r}


train <- read.csv("train.csv")
library(caret)

set.seed(123)
trainIndex <- createDataPartition(train$SalePrice, p = 0.8, list = FALSE)
trainData <- train[trainIndex, ]
testData <- train[-trainIndex, ]
correlations <-
library(corrplot)
corr_matrix <- cor(trainData[, sapply(trainData, is.numeric)])
corrplot(corr_matrix, method = "color")

```

De acuerdo con la matriz de correlación, las variables GarageYrBlt y YearBuilt tienen una correlación muy alta de 0.83. Esto indica que estas dos variables están muy relacionadas entre sí y pueden estar contribuyendo a la multicolinealidad en el modelo.

Las variables con un valor de p menor a 0.05 son consideradas significativas para el modelo. En este caso, las variables MSSubClass, LotFrontage, LotArea, OverallQual, OverallCond, YearBuilt, BsmtFinSF1, 1stFlrSF, GrLivArea, BsmtFullBath, FullBath, HalfBath, TotRmsAbvGrd, Fireplaces, GarageCars, GarageArea, WoodDeckSF, OpenPorchSF, EnclosedPorch, ScreenPorch, MoSold, y YrSold tienen valores de p menores a 0.05 y, por lo tanto, se consideran significativas para el modelo.





***Ejericicio 10 ***
Si tiene multicolinealidad o sobreajuste, haga un modelo con las variables que sean mejores
predictoras del precio de las casas. Determine la calidad del modelo realizando un análisis
de los residuos. Muéstrelo gráficamente.

```{r}
# Cargar los datos y ajustar el modelo
train <- read.csv("train.csv")
library(caret)
set.seed(123)
trainIndex <- createDataPartition(train$SalePrice, p = 0.8, list = FALSE)
trainData <- train[trainIndex, ]
testData <- train[-trainIndex, ]
predictors <- c("OverallQual", "GrLivArea", "GarageCars", "TotalBsmtSF", "FullBath", "YearBuilt")
lm.fit <- lm(SalePrice ~ ., data = trainData[, c(predictors, "SalePrice")])

# Graficar los residuos
par(mfrow = c(2, 2))
plot(lm.fit$residuals, pch = 20, main = "Residuals vs Fitted")
plot(lm.fit$fitted.values, lm.fit$residuals, pch = 20, main = "Residuals vs Fitted Values")
qqnorm(lm.fit$residuals, main = "Normal Q-Q Plot")
qqline(lm.fit$residuals)
hist(lm.fit$residuals, main = "Histogram of Residuals")



```


El el primer grafico "Residuals vs Fitted" podemos observar que no hay un patron claro en los datos, por lo que podemos sujerir que el modelo puede ser apropiado para los datos. Posteriormente en el gráfico de "Residuals vs Fitted Values" , se ve como los puntos estan distribuidos aleatoriamente sobre la linea cero, lo que nos dice que la varianza de error es constante en todos los niveles del predictor, es decir esta varianza del error es constante, esto simplemente nos corrobora el hecho que el error no está variando demasiado entre predicciones. En la grafica "Normal Q-Q Plot" se nos muestra si los residuos se distribuyen normalmente, en este caso dado que están ajustados casi en linea recta podemos asumir que se da esta observación. Para la gráfica "Histogram of Residuals" se nos muestra una grafica donde podemos ver la distribución de los residuos, dado que el gráfica esta aproximadamente en una forma de campana podemos suponer que el modelo es adecuado para los datos.


***Ejercicio 11 ***

Utilice cada modelo con el conjunto de prueba y determine la eficiencia del algoritmo para
predecir el precio de las casas. ¿Qué tan bien lo hizo?


***Modelo 1 ***

```{R}
predictions <- predict(lm_model, na.omit(testData[, sapply(testData, is.numeric)]))
R2 <- summary(lm_model)$r.squared
MSE <- mean((predictions - testData$SalePrice)^2)
cat(paste0("R cuadrado: ", round(R2, 3), "\n"))
cat(paste0("MSE: ", round(MSE, 3), "\n"))
```

El modelo 1 utiliza todas las variables numéricas del conjunto de datos y muestra un R cuadrado de 0.836 y un MSE de 14555852465. Esto indica que el modelo explica aproximadamente el 86% de la variabilidad en el conjunto de prueba y tiene un error medio cuadrático de alrededor de 1.33 billones de dólares.

***Modelo 2***
```{r}
predictions <- predict(lm.fit, testData[, c(predictors)])
R2 <- summary(lm.fit)$r.squared
MSE <- mean((predictions - testData$SalePrice)^2)
cat(paste0("R cuadrado: ", round(R2, 3), "\n"))
cat(paste0("MSE: ", round(MSE, 3), "\n"))

```

El modelo 2 utiliza un conjunto específico de variables predictoras y muestra un R cuadrado de 0.78 y un MSE de 223274775. Esto indica que el modelo explica aproximadamente el 84% de la variabilidad en el conjunto de prueba y tiene un error medio cuadrático de alrededor de 1.45 billones de dólares.

En general, ambos modelos tienen un buen desempeño al predecir el precio de las casas, pero el modelo 1 parece ser ligeramente mejor en términos de R cuadrado y MSE. Sin embargo, se puede considerar que el modelo 2 es más fácil de interpretar debido a que utiliza un conjunto específico de variables predictoras seleccionadas previamente.


